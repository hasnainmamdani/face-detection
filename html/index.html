<html>
<head>
<title>MSBD6000C Project3 </title>
<link href='http://fonts.googleapis.com/css?family=Nunito:300|Crimson+Text|Droid+Sans+Mono' rel='stylesheet' type='text/css'>
<link rel="stylesheet" title="Default" href="styles/github.css">
<script src="http://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js"></script>  

<link rel="stylesheet" href="highlighting/styles/default.css">
<script src="highlighting/highlight.pack.js"></script>

<style type="text/css">
body {
	margin: 0px;
	width: 100%;
	font-family: 'Crimson Text', serif;
	font-size: 20px;
	background: #fcfcfc;
}
h1 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 28px;
	margin: 25px 0px 0px 0px;
	text-transform: lowercase;

}

h2 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 32px;
	margin: 15px 0px 35px 0px;
	color: #333;	
	word-spacing: 3px;
}

h3 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 26px;
	margin: 10px 0px 10px 0px;
	color: #333;
	word-spacing: 2px;
}
h4 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 22px;
	margin: 10px 0px 10px 0px;
	color: #333;
	word-spacing: 2px;
}

h5 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 18px;
	margin: 10px 0px 10px 0px;
	color: #111;
	word-spacing: 2px;
}

p, li {
	color: #444;
}

a {
	color: #DE3737;
}

.container {
	margin: 0px auto 0px auto;
	width: 1160px;
}

#header {
	background: #333;
	width: 100%;
}

#headersub {
	color: #ccc;
	width: 960px;
	margin: 0px auto 0px auto;
	padding: 20px 0px 20px 0px;
}

.chart {
	width: 480px;
}
.lol {
	font-size: 16px;
	color: #888;
	font-style: italic;
}
.sep {
	height: 1px;
	width: 100%;
	background: #999;
	margin: 20px 0px 20px 0px;
}
.footer{
	font-size: 16px;
}
.latex {
	width: 100%;
}

.latex img {
	display: block;
	margin: 0px auto 0px auto;
}

pre {
	font-family: 'Droid Sans Mono';
	font-size: 14px;
}

table td {
  text-align: center;
  vertical-align: middle;
}

table td img {
  text-align: center;
  vertical-align: middle;
}

#contents a {
}
</style>
<script type="text/javascript">
    hljs.initHighlightingOnLoad();
</script>
</head>
<body>
<div id="header" >
<div id="headersub">
<h1>KaHo LAU <span style="color: #DE3737">20094423</span></h1>
<h1>Mamdani, Muhammad Hasnain <span style="color: #DE3737">(your cs id)</span></h1>
</div>
</div>
<div class="container">

<h2>MSBD6000C Project 3 Face Detection </h2>

<!--
<div style="float: right; padding: 20px">
<img src="placeholder.jpg" />
<p style="font-size: 14px">Example of a right floating element.</p>
</div>
-->
<h3>Part 1: Positive Feature Extraction</h3>
<p> 	Extract positive feature from 36x36 face only images. We use vl_hog from vlfeat library to extract the HoG descriptors.</p>
<pre><code>
for i = 1:num_images
    img = imread(strcat(train_path_pos, '/', image_files(i).name));
    img = single(img)/255;
    if (size(img, 3) > 1)
        img = rgb2gray(img);
    end
    feat = vl_hog(img, feature_params.hog_cell_size);
    reshaped_feat = reshape(feat, 1, []);
    features_pos(2*i-1,:) = reshaped_feat;

    % mirroring the faces along the y axis
    feat_flip = vl_hog(flipdim(img, 2), feature_params.hog_cell_size);
    reshaped_feat_flip = reshape(feat_flip, 1, []);
    
</code></pre>

<h3>Part 2: Negative Feature Extraction</h3>
<p> 	Extract negative feature from 36x36 face only images. We use vl_hog from vlfeat library to extract the HoG descriptors. We first estimate the number of sample per non-face image. Then, we randomly sample each image with different scale([1 0.8 .06 .04]). Finally, we will randomly pick up the required number of sample since each image is sampled multiple time according to scale  </p>
<pre><code>
% Find number of samples per image
num_samples_per_image = ceil(num_samples / num_images);

% Size of each sample patch
patch_size = feature_params.template_size;

initial_num_samples = num_samples;
%[1 0.8 0.6 0.4]
scales = 1:-0.2:0.4;
count = 0 ;
for i = 1:num_images
    img = imread(strcat(non_face_scn_path, '/', image_files(i).name));
    if (size(img, 3) > 1)
        img = rgb2gray(img);
    end

    for scale_index = 1:length(scales)
        scale = scales(scale_index);
        scaled_img = imresize(img, scale);
        img_size = size(scaled_img);
        
        if img_size(1) < feature_params.template_size || img_size(2) < feature_params.template_size
            break
        end

        [y, x] = size(scaled_img);
	    for j = 1 : ceil(num_samples_per_image * scale)
	        small_img = img(randi(y - patch_size + 1) + (0 : patch_size - 1), randi(x - patch_size + 1) + (0 : patch_size - 1));
            feat = vl_hog(single(small_img), feature_params.hog_cell_size);
            reshaped_feat = reshape(feat, 1, []);
            count = count + 1;
            if count>=num_samples
                % resize features_neg
                num_samples = num_samples + initial_num_samples;
                temp = features_neg;
                features_neg = zeros(num_samples, dims);
                features_neg(1:size(temp, 1), :) = temp;
            end
	        features_neg(count, :) = reshaped_feat;
        end

    end
end
indices = randperm(count);
features_neg = features_neg(indices,:);
features_neg = features_neg(1:initial_num_samples, :);
    
</code></pre>


<h3>Part 3: Training SVM</h3>
<p> 	We train the svm classifier using the feature extracted in previous parts</p>
<pre><code>
lambda = 0.0001;
%Training Data:
X = [features_pos; features_neg];
%Training Label:
Y = [ones(size(features_pos, 1), 1); -1 * ones(size(features_neg, 1), 1)];
%Collect Data to SVM:
[w b] = vl_svmtrain(X', Y', lambda);
    
</code></pre>




<h3>Results in a table</h3>

<table border=1>
<tr>
<td>
<img src="placeholder.jpg" width="24%"/>
<img src="placeholder.jpg"  width="24%"/>
<img src="placeholder.jpg" width="24%"/>
<img src="placeholder.jpg" width="24%"/>
</td>
</tr>

<tr>
<td>
<img src="placeholder.jpg" width="24%"/>
<img src="placeholder.jpg"  width="24%"/>
<img src="placeholder.jpg" width="24%"/>
<img src="placeholder.jpg" width="24%"/>
</td>
</tr>

</table>

<center>
<p>
Face template HoG visualization for the starter code. This is completely random, but it should actually look like a face once you train a reasonable classifier.
<p>
<img src="hog_template.png">
<p>
Precision Recall curve for the starter code.
<p>
<img src="average_precision.png">
<p>
Example of detection on the test set from the starter code.
<img src="detections_Argentina.jpg.png">

</center>

<div style="clear:both" >
<p> 	Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>
</div>
</body>
</html>
